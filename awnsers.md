# TP WOOGLE

## II/ Crawling the data

1. the wikipedia category that will be crawled is : Biology
2. a file named "wiki.lst" and the number of pages crawled by depth
3. wiki.lst contains all titles of the crawled pages

## III/Downloading the data

1. batch are of size 3000
2. the API of wikipedia used is "https://en.wikipedia.org/wiki/Special:Export"
3.
